"""
ä¸šåŠ¡å¤„ç†å™¨ - Excel è½¬æ¢å’Œé¢„è§ˆ
ä½¿ç”¨ç±»å°è£…çŠ¶æ€ï¼Œæ¶ˆé™¤å…¨å±€å˜é‡
"""

import shutil
import tempfile
from dataclasses import dataclass, field
from pathlib import Path

from loguru import logger

from src.core.excel2html.chunker import distribute_assets_and_chunk
from src.core.excel2html.converter import convert_excel_to_html
from src.core.models import ProcessingState, SplitMode


@dataclass
class ExcelProcessHandler:
    """Excel å¤„ç†å™¨"""

    state: ProcessingState = field(default_factory=ProcessingState)

    def process(
        self,
        excel_file,
        keywords_text: str,
        split_mode: str,
        max_rows: int,
        target_tokens: int,
        enable_min_tokens: bool,
        min_tokens: int,
        token_strategy: str,
        separator: str,
    ) -> tuple[str | None, str | None, str]:
        """å¤„ç† Excel æ–‡ä»¶"""
        if excel_file is None:
            return None, None, "âš ï¸ è¯·å…ˆä¸Šä¼  Excel æ–‡ä»¶"

        keywords = self._parse_keywords(keywords_text)
        temp_dir = Path(tempfile.mkdtemp())

        try:
            result = self._execute_conversion(
                excel_file,
                temp_dir,
                keywords,
                split_mode,
                max_rows,
                target_tokens,
                enable_min_tokens,
                min_tokens,
                token_strategy,
                separator,
            )
            return result
        except Exception as e:
            logger.exception("å¤„ç†å‡ºé”™")
            self._reset_state()
            return None, None, f"âŒ å¤„ç†å‡ºé”™: {e!s}"

    def _parse_keywords(self, keywords_text: str) -> list[str] | None:
        """è§£æå…³é”®è¯"""
        if not keywords_text.strip():
            return None
        return [k.strip() for k in keywords_text.split(",") if k.strip()]

    def _execute_conversion(
        self,
        excel_file,
        temp_dir: Path,
        keywords: list[str] | None,
        split_mode: str,
        max_rows: int,
        target_tokens: int,
        enable_min_tokens: bool,
        min_tokens: int,
        token_strategy: str,
        separator: str,
    ) -> tuple[str | None, str | None, str]:
        """æ‰§è¡Œè½¬æ¢æµç¨‹"""
        # å¤åˆ¶æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        source_path = Path(excel_file.name)
        temp_excel = temp_dir / source_path.name
        shutil.copy(excel_file.name, temp_excel)

        # Excel -> HTML
        html_path = convert_excel_to_html(
            excel_path=str(temp_excel),
            keywords=keywords,
            output_path=None,
        )

        if not html_path:
            return None, None, "âŒ Excel è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼"

        html_content = Path(html_path).read_text(encoding="utf-8")

        # HTML -> Chunks
        result = self._chunk_html(
            html_content,
            split_mode,
            max_rows,
            target_tokens,
            enable_min_tokens,
            min_tokens,
            token_strategy,
        )

        if isinstance(result, str):  # é”™è¯¯æ¶ˆæ¯
            return None, None, result

        chunks, warnings, stats = result

        # ä¿å­˜ç»“æœ
        return self._save_results(
            source_path,
            temp_dir,
            html_path,
            chunks,
            warnings,
            stats,
            keywords,
            split_mode,
            enable_min_tokens,
            min_tokens,
            token_strategy,
            separator,
        )

    def _chunk_html(
        self,
        html_content: str,
        split_mode: str,
        max_rows: int,
        target_tokens: int,
        enable_min_tokens: bool,
        min_tokens: int,
        token_strategy: str,
    ) -> tuple[list[str], list[dict], dict] | str:
        """åˆ‡åˆ† HTML"""
        if split_mode == SplitMode.BY_TOKENS:
            min_tokens_value = min_tokens if enable_min_tokens else None

            if min_tokens_value is not None and min_tokens_value >= target_tokens:
                return (
                    f"âŒ æœ€å° Token æ•° ({min_tokens_value}) å¿…é¡»å°äºæœ€å¤§ Token æ•° ({target_tokens})"
                )

            strategy = "prefer_max" if token_strategy == "æ¥è¿‘æœ€å¤§å€¼" else "prefer_min"

            result = distribute_assets_and_chunk(
                html_content,
                max_rows_per_chunk=None,
                max_tokens_per_chunk=target_tokens,
                min_tokens_per_chunk=min_tokens_value,
                token_strategy=strategy,
            )
        else:
            result = distribute_assets_and_chunk(
                html_content,
                max_rows_per_chunk=max_rows,
                max_tokens_per_chunk=None,
            )

        return result["chunks"], result["warnings"], result["stats"]

    def _save_results(
        self,
        source_path: Path,
        temp_dir: Path,
        html_path: str,
        chunks: list[str],
        warnings: list[dict],
        stats: dict,
        keywords: list[str] | None,
        split_mode: str,
        enable_min_tokens: bool,
        min_tokens: int,
        token_strategy: str,
        separator: str,
    ) -> tuple[str, str, str]:
        """ä¿å­˜ç»“æœæ–‡ä»¶"""
        formatted_separator = f"\n\n{separator}\n\n"
        merged_content = formatted_separator.join(chunks)

        html_output_name = f"{source_path.stem}_middle.html"
        chunk_output_name = f"{source_path.stem}.html"

        chunk_path = temp_dir / chunk_output_name
        chunk_path.write_text(merged_content, encoding="utf-8")

        html_final_path = temp_dir / html_output_name
        if str(html_path) != str(html_final_path):
            shutil.copy(html_path, html_final_path)
            html_path = str(html_final_path)

        self.state.html_path = Path(html_path)
        self.state.chunk_path = chunk_path

        status = self._build_status_message(
            source_path,
            keywords,
            split_mode,
            enable_min_tokens,
            min_tokens,
            token_strategy,
            chunks,
            stats,
            warnings,
            separator,
        )

        return html_path, str(chunk_path), status

    def _build_status_message(
        self,
        source_path: Path,
        keywords: list[str] | None,
        split_mode: str,
        enable_min_tokens: bool,
        min_tokens: int,
        token_strategy: str,
        chunks: list[str],
        stats: dict,
        warnings: list[dict],
        separator: str,
    ) -> str:
        """æ„å»ºçŠ¶æ€æ¶ˆæ¯"""
        warning_text = ""
        if warnings:
            warning_text = f"\nâš ï¸ è­¦å‘Šï¼š{len(warnings)} ä¸ªç‰‡æ®µè¶…è¿‡ token é™åˆ¶"
            for w in warnings:
                warning_text += (
                    f"\n   - ç‰‡æ®µ #{w['chunk_index']}: "
                    f"{w['actual_tokens']} tokens (è¶…å‡º {w['overflow']})"
                )

        min_token_info = ""
        if split_mode == SplitMode.BY_TOKENS and enable_min_tokens:
            min_token_info = f"\næœ€å° Tokenï¼š{min_tokens}ï¼Œç­–ç•¥ï¼š{token_strategy}"

        return f"""âœ… å¤„ç†å®Œæˆ

æºæ–‡ä»¶ï¼š{source_path.name}
å…³é”®è¯ï¼š{", ".join(keywords) if keywords else "æ— "}
åˆ‡åˆ†æ¨¡å¼ï¼š{split_mode}{min_token_info}
ç”Ÿæˆ Chunksï¼š{len(chunks)} ä¸ª
Token ç»Ÿè®¡ï¼šæœ€å°={stats["min_token_count"]}, æœ€å¤§={stats["max_token_count"]}, å¹³å‡={stats["avg_token_count"]:.1f}
åˆ†éš”ç¬¦ï¼š{separator}{warning_text}"""

    def _reset_state(self) -> None:
        """é‡ç½®çŠ¶æ€"""
        self.state.html_path = None
        self.state.chunk_path = None

    def get_html_preview(self) -> str | None:
        """è·å– HTML é¢„è§ˆå†…å®¹"""
        if self.state.html_path and self.state.html_path.exists():
            content = self.state.html_path.read_text(encoding="utf-8")
            return self._wrap_preview_html("ä¸­é—´ç»“æœé¢„è§ˆ", content)
        return None

    def get_chunk_preview(self) -> str | None:
        """è·å– Chunk é¢„è§ˆå†…å®¹"""
        if self.state.chunk_path and self.state.chunk_path.exists():
            content = self.state.chunk_path.read_text(encoding="utf-8")
            content = content.replace(
                "!!!_CHUNK_BREAK_!!!",
                '</div><hr style="border: 2px dashed #2563eb; margin: 40px 0;">'
                '<div style="background:#f8f9fa; padding: 8px 16px; border-radius: 4px; '
                'color: #666; font-size: 0.85rem; margin-bottom: 20px;">ğŸ“¦ Chunk åˆ†éš”</div>'
                '<div class="chunk">',
            )
            return self._wrap_preview_html("Chunks é¢„è§ˆ", f'<div class="chunk">{content}</div>')
        return None

    def _wrap_preview_html(self, title: str, content: str) -> str:
        """åŒ…è£…é¢„è§ˆ HTML"""
        return f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>{title}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; padding: 40px; max-width: 1200px; margin: auto; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
        th {{ background: #f5f5f5; font-weight: 600; }}
        tr:hover {{ background: #fafafa; }}
        .rag-context {{ background: #e3f2fd; padding: 16px; border-radius: 8px; margin-bottom: 20px; color: #1565c0; }}
        caption {{ font-size: 0.9rem; color: #666; margin-bottom: 12px; }}
        .chunk {{ margin-bottom: 20px; }}
    </style>
</head>
<body>
    <h2>ğŸ“„ {title}</h2>
    {content}
</body>
</html>"""


# å…¨å±€å¤„ç†å™¨å®ä¾‹ï¼ˆç”¨äº Gradio å›è°ƒï¼‰
_handler: ExcelProcessHandler | None = None


def _get_handler() -> ExcelProcessHandler:
    """è·å–å¤„ç†å™¨å®ä¾‹"""
    global _handler
    if _handler is None:
        _handler = ExcelProcessHandler()
    return _handler


def process_excel(
    excel_file,
    keywords_text: str,
    split_mode: str,
    max_rows: int,
    target_tokens: int,
    enable_min_tokens: bool,
    min_tokens: int,
    token_strategy: str,
    separator: str,
) -> tuple[str | None, str | None, str]:
    """å¤„ç† Excel æ–‡ä»¶ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
    return _get_handler().process(
        excel_file,
        keywords_text,
        split_mode,
        max_rows,
        target_tokens,
        enable_min_tokens,
        min_tokens,
        token_strategy,
        separator,
    )


def get_html_preview() -> str | None:
    """è·å– HTML é¢„è§ˆï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
    return _get_handler().get_html_preview()


def get_chunk_preview() -> str | None:
    """è·å– Chunk é¢„è§ˆï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
    return _get_handler().get_chunk_preview()
