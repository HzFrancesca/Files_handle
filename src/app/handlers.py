"""
ä¸šåŠ¡å¤„ç†å™¨ - Excel è½¬æ¢å’Œé¢„è§ˆ
ä½¿ç”¨ç±»å°è£…çŠ¶æ€ï¼Œæ¶ˆé™¤å…¨å±€å˜é‡
"""

import shutil
import tempfile
from dataclasses import dataclass, field
from pathlib import Path

from loguru import logger

from src.core.models import OutputFormat, ProcessingState, SplitMode
from src.core.unified_pipeline import UnifiedPipeline


@dataclass
class ExcelProcessHandler:
    """Excel å¤„ç†å™¨"""

    state: ProcessingState = field(default_factory=ProcessingState)

    def process(
        self,
        excel_file,
        output_format: str,
        keywords_text: str,
        split_mode: str,
        max_rows: int,
        target_tokens: int,
        enable_min_tokens: bool,
        min_tokens: int,
        token_strategy: str,
        separator: str,
    ) -> tuple[str | None, str | None, str]:
        """å¤„ç† Excel æ–‡ä»¶"""
        if excel_file is None:
            return None, None, "âš ï¸ è¯·å…ˆä¸Šä¼  Excel æ–‡ä»¶"

        keywords = self._parse_keywords(keywords_text)
        temp_dir = Path(tempfile.mkdtemp())

        try:
            result = self._execute_conversion(
                excel_file,
                temp_dir,
                output_format,
                keywords,
                split_mode,
                max_rows,
                target_tokens,
                enable_min_tokens,
                min_tokens,
                token_strategy,
                separator,
            )
            return result
        except Exception as e:
            logger.exception("å¤„ç†å‡ºé”™")
            self._reset_state()
            return None, None, f"âŒ å¤„ç†å‡ºé”™: {e!s}"

    def _parse_keywords(self, keywords_text: str) -> list[str] | None:
        """è§£æå…³é”®è¯"""
        if not keywords_text.strip():
            return None
        return [k.strip() for k in keywords_text.split(",") if k.strip()]

    def _execute_conversion(
        self,
        excel_file,
        temp_dir: Path,
        output_format: str,
        keywords: list[str] | None,
        split_mode: str,
        max_rows: int,
        target_tokens: int,
        enable_min_tokens: bool,
        min_tokens: int,
        token_strategy: str,
        separator: str,
    ) -> tuple[str | None, str | None, str]:
        """æ‰§è¡Œè½¬æ¢æµç¨‹"""
        # å¤åˆ¶æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        source_path = Path(excel_file.name)
        temp_excel = temp_dir / source_path.name
        shutil.copy(excel_file.name, temp_excel)

        # è§£æè¾“å‡ºæ ¼å¼
        fmt = OutputFormat(output_format)

        # ä½¿ç”¨ç»Ÿä¸€æµæ°´çº¿
        pipeline = UnifiedPipeline(
            output_format=fmt,
            keywords=keywords,
            max_rows_per_chunk=max_rows if split_mode == SplitMode.BY_ROWS else None,
            target_tokens=target_tokens,
            separator=separator,
        )

        result = pipeline.run(temp_excel)

        if not result or not result.success:
            return None, None, "âŒ è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼"

        # é‡å‘½åè¾“å‡ºæ–‡ä»¶
        ext_map = {
            OutputFormat.HTML: ".html",
            OutputFormat.MARKDOWN: ".md",
        }
        ext = ext_map[fmt]

        # HTML/MD æ ¼å¼æœ‰ä¸­é—´ç»“æœå’Œæœ€ç»ˆç»“æœ
        middle_output_name = f"{source_path.stem}_middle{ext}"
        final_output_name = f"{source_path.stem}{ext}"
        middle_path = temp_dir / middle_output_name
        final_path = temp_dir / final_output_name

        if result.output_path and result.output_path.exists():
            # é¿å…å¤åˆ¶åˆ°è‡ªèº«
            if result.output_path.resolve() != middle_path.resolve():
                shutil.copy(result.output_path, middle_path)
            else:
                middle_path = result.output_path
        if result.chunk_path and result.chunk_path.exists():
            # é¿å…å¤åˆ¶åˆ°è‡ªèº«
            if result.chunk_path.resolve() != final_path.resolve():
                shutil.copy(result.chunk_path, final_path)
            else:
                final_path = result.chunk_path

        self.state.html_path = middle_path
        self.state.chunk_path = final_path
        self.state.output_format = fmt

        status = self._build_status_message(
            source_path,
            fmt,
            keywords,
            split_mode,
            enable_min_tokens,
            min_tokens,
            token_strategy,
            result.chunk_count,
            separator,
            result.chunk_stats,
        )

        return str(middle_path), str(final_path), status

    def _build_status_message(
        self,
        source_path: Path,
        output_format: OutputFormat,
        keywords: list[str] | None,
        split_mode: str,
        enable_min_tokens: bool,
        min_tokens: int,
        token_strategy: str,
        chunk_count: int,
        separator: str,
        chunk_stats=None,
    ) -> str:
        """æ„å»ºçŠ¶æ€æ¶ˆæ¯"""
        format_names = {
            OutputFormat.HTML: "HTML",
            OutputFormat.MARKDOWN: "Markdown",
        }

        min_token_info = ""
        if split_mode == SplitMode.BY_TOKENS and enable_min_tokens:
            min_token_info = f"\næœ€å° Tokenï¼š{min_tokens}ï¼Œç­–ç•¥ï¼š{token_strategy}"

        chunking_info = f"\nåˆ‡åˆ†æ¨¡å¼ï¼š{split_mode}{min_token_info}"
        chunking_info += f"\nç”Ÿæˆ Chunksï¼š{chunk_count} ä¸ª"
        if chunk_stats:
            chunking_info += f"\nToken ç»Ÿè®¡ï¼šæœ€å°={chunk_stats.min_token_count}, æœ€å¤§={chunk_stats.max_token_count}, å¹³å‡={chunk_stats.avg_token_count:.1f}"
        chunking_info += f"\nåˆ†éš”ç¬¦ï¼š{separator}"

        return f"""âœ… å¤„ç†å®Œæˆ

æºæ–‡ä»¶ï¼š{source_path.name}
è¾“å‡ºæ ¼å¼ï¼š{format_names[output_format]}
å…³é”®è¯ï¼š{", ".join(keywords) if keywords else "æ— "}{chunking_info}"""

    def _reset_state(self) -> None:
        """é‡ç½®çŠ¶æ€"""
        self.state.html_path = None
        self.state.chunk_path = None
        self.state.output_format = OutputFormat.HTML

    def get_html_preview(self) -> str | None:
        """è·å–ä¸­é—´ç»“æœé¢„è§ˆå†…å®¹"""
        if self.state.html_path and self.state.html_path.exists():
            content = self.state.html_path.read_text(encoding="utf-8")
            is_markdown = self.state.output_format == OutputFormat.MARKDOWN
            return self._wrap_preview_html("ä¸­é—´ç»“æœé¢„è§ˆ", content, is_markdown)
        return None

    def get_chunk_preview(self) -> str | None:
        """è·å–æœ€ç»ˆç»“æœé¢„è§ˆå†…å®¹"""
        if self.state.chunk_path and self.state.chunk_path.exists():
            content = self.state.chunk_path.read_text(encoding="utf-8")
            is_markdown = self.state.output_format == OutputFormat.MARKDOWN

            return self._wrap_preview_html("Chunks é¢„è§ˆ", content, is_markdown)
        return None

    def _wrap_preview_html(self, title: str, content: str, is_markdown: bool = False) -> str:
        """åŒ…è£…é¢„è§ˆ HTML"""
        if is_markdown:
            # Markdown å†…å®¹ç”¨ <pre> åŒ…è£¹ä¿ç•™æ ¼å¼
            escaped_content = content.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
            body_content = f'<pre class="markdown-preview">{escaped_content}</pre>'
        else:
            body_content = content

        return f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>{title}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; padding: 40px; max-width: 1200px; margin: auto; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
        th {{ background: #f5f5f5; font-weight: 600; }}
        tr:hover {{ background: #fafafa; }}
        .rag-context {{ background: #e3f2fd; padding: 16px; border-radius: 8px; margin-bottom: 20px; color: #1565c0; }}
        caption {{ font-size: 0.9rem; color: #666; margin-bottom: 12px; }}
        .chunk {{ margin-bottom: 20px; }}
        pre {{ background: #f5f5f5; padding: 16px; border-radius: 8px; overflow-x: auto; font-family: monospace; }}
        .markdown-preview {{ white-space: pre-wrap; word-wrap: break-word; line-height: 1.6; font-size: 14px; }}
    </style>
</head>
<body>
    <h2>ğŸ“„ {title}</h2>
    {body_content}
</body>
</html>"""


# å…¨å±€å¤„ç†å™¨å®ä¾‹ï¼ˆç”¨äº Gradio å›è°ƒï¼‰
_handler: ExcelProcessHandler | None = None


def _get_handler() -> ExcelProcessHandler:
    """è·å–å¤„ç†å™¨å®ä¾‹"""
    global _handler
    if _handler is None:
        _handler = ExcelProcessHandler()
    return _handler


def process_excel(
    excel_file,
    output_format: str,
    keywords_text: str,
    split_mode: str,
    max_rows: int,
    target_tokens: int,
    enable_min_tokens: bool,
    min_tokens: int,
    token_strategy: str,
    separator: str,
) -> tuple[str | None, str | None, str]:
    """å¤„ç† Excel æ–‡ä»¶"""
    return _get_handler().process(
        excel_file,
        output_format,
        keywords_text,
        split_mode,
        max_rows,
        target_tokens,
        enable_min_tokens,
        min_tokens,
        token_strategy,
        separator,
    )


def get_html_preview() -> str | None:
    """è·å–ä¸­é—´ç»“æœé¢„è§ˆ"""
    return _get_handler().get_html_preview()


def get_chunk_preview() -> str | None:
    """è·å–æœ€ç»ˆç»“æœé¢„è§ˆ"""
    return _get_handler().get_chunk_preview()
