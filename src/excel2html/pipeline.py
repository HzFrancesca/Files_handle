"""
Excel è½¬ HTML å®Œæ•´æµæ°´çº¿
è¾“å…¥ Excel æ–‡ä»¶ -> ç”Ÿæˆå¢å¼º HTML -> åˆ‡åˆ†ä¸º Chunks

ä¸­é—´ç»“æœå‘½å: åŸæ–‡ä»¶å_converted.html
æœ€ç»ˆç»“æœå‘½å: åŸæ–‡ä»¶å.htmlï¼ˆä¸åŸæ–‡ä»¶åŒåï¼Œæ–¹ä¾¿ç›´æ¥ä½¿ç”¨ï¼‰
"""

from pathlib import Path
import argparse

from excel2html_openpyxl_enhanced import convert_excel_to_html
from html2chunk import distribute_assets_and_chunk, estimate_tokens


def estimate_rows_for_token_limit(html_content: str, target_tokens: int = 512) -> int:
    """
    æ ¹æ®ç›®æ ‡ token æ•°ä¼°ç®—æ¯ä¸ª chunk åº”è¯¥åŒ…å«å¤šå°‘è¡Œ

    å‚æ•°:
        html_content: å®Œæ•´çš„ HTML å†…å®¹
        target_tokens: ç›®æ ‡ token æ•°ï¼ˆé»˜è®¤ 512ï¼‰

    è¿”å›:
        å»ºè®®çš„ max_rows_per_chunk
    """
    from bs4 import BeautifulSoup

    soup = BeautifulSoup(html_content, "html.parser")

    # è®¡ç®—å›ºå®šå¼€é”€ï¼ˆcontext + caption + theadï¼‰
    fixed_parts = []

    context_div = soup.find("div", class_="rag-context")
    if context_div:
        fixed_parts.append(str(context_div))

    table = soup.find("table")
    if not table:
        return 8  # æ— è¡¨æ ¼ï¼Œè¿”å›é»˜è®¤å€¼

    caption = table.find("caption")
    if caption:
        fixed_parts.append(str(caption))

    thead = table.find("thead")
    if thead:
        fixed_parts.append(str(thead))

    fixed_overhead = estimate_tokens("".join(fixed_parts))

    # è®¡ç®—æ¯è¡Œå¹³å‡ token
    tbody = table.find("tbody")
    if tbody:
        data_rows = tbody.find_all("tr")
    else:
        all_rows = table.find_all("tr")
        data_rows = all_rows[1:] if len(all_rows) > 1 else all_rows

    if not data_rows:
        return 8

    total_row_tokens = sum(estimate_tokens(str(row)) for row in data_rows)
    avg_tokens_per_row = total_row_tokens / len(data_rows)

    # è®¡ç®—å¯ç”¨äºæ•°æ®è¡Œçš„ token æ•°
    available_tokens = target_tokens - fixed_overhead

    if available_tokens <= 0 or avg_tokens_per_row <= 0:
        return 1  # æç«¯æƒ…å†µï¼Œæ¯ä¸ª chunk åªæ”¾ 1 è¡Œ

    suggested_rows = int(available_tokens / avg_tokens_per_row)

    # é™åˆ¶åœ¨åˆç†èŒƒå›´ [1, 20]
    return max(1, min(suggested_rows, 20))


def run_pipeline(
    excel_path: str,
    keywords: list = None,
    max_rows_per_chunk: int = None,
    target_tokens: int = 512,
    separator: str = "!!!_CHUNK_BREAK_!!!",
):
    """
    æ‰§è¡Œå®Œæ•´çš„ Excel -> HTML -> Chunks æµæ°´çº¿

    å‚æ•°:
        excel_path: Excel æ–‡ä»¶è·¯å¾„
        keywords: å…³é”®æ£€ç´¢è¯åˆ—è¡¨ï¼ˆç”¨äºå¹½çµæ ‡é¢˜ï¼‰
        max_rows_per_chunk: æ¯ä¸ª chunk çš„æœ€å¤§è¡Œæ•°ï¼ˆå¦‚æœæŒ‡å®šï¼Œä¼˜å…ˆä½¿ç”¨ï¼‰
        target_tokens: ç›®æ ‡ token æ•°ï¼ˆå½“ max_rows æœªæŒ‡å®šæ—¶ï¼Œè‡ªåŠ¨è®¡ç®—è¡Œæ•°ï¼‰
        separator: chunk ä¹‹é—´çš„åˆ†éš”ç¬¦

    è¿”å›:
        dict: {
            'html_path': ä¸­é—´ HTML æ–‡ä»¶è·¯å¾„,
            'chunk_path': æœ€ç»ˆ chunk æ–‡ä»¶è·¯å¾„,
            'chunk_count': chunk æ•°é‡
        }
    """
    source_path = Path(excel_path)

    if not source_path.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ '{source_path}'")
        return None

    print("=" * 50)
    print(f"ğŸš€ å¼€å§‹å¤„ç†æµæ°´çº¿: {source_path.name}")
    print("=" * 50)

    # === ç¬¬ä¸€æ­¥ï¼šExcel -> HTML ===
    print("\nğŸ“Œ ç¬¬ä¸€æ­¥ï¼šExcel è½¬ HTMLï¼ˆå¢å¼ºç‰ˆï¼‰")
    html_path = convert_excel_to_html(
        excel_path=str(source_path),
        keywords=keywords,
        output_path=None,  # é»˜è®¤ä¿å­˜åˆ°åŒç›®å½•
    )

    if not html_path:
        print("âŒ æµæ°´çº¿ä¸­æ–­ï¼šHTML è½¬æ¢å¤±è´¥")
        return None

    # === ç¬¬äºŒæ­¥ï¼šHTML -> Chunks ===
    print("\nğŸ“Œ ç¬¬äºŒæ­¥ï¼šHTML åˆ‡åˆ†ä¸º Chunks")
    html_content = Path(html_path).read_text(encoding="utf-8")

    # è‡ªåŠ¨è®¡ç®—æˆ–ä½¿ç”¨æŒ‡å®šçš„è¡Œæ•°
    if max_rows_per_chunk is None:
        # ä½¿ç”¨ token æ¨¡å¼ï¼šé€è¡Œç´¯åŠ ï¼Œç²¾ç¡®æ§åˆ¶æ¯ä¸ª chunk çš„ token æ•°
        print(f"ğŸ“Š ä½¿ç”¨ token æ¨¡å¼ï¼Œç›®æ ‡æ¯ chunk â‰¤ {target_tokens} tokens")
        chunks = distribute_assets_and_chunk(
            html_content,
            max_rows_per_chunk=None,
            max_tokens_per_chunk=target_tokens
        )
    else:
        # ä½¿ç”¨è¡Œæ•°æ¨¡å¼
        print(f"ğŸ“Š ä½¿ç”¨è¡Œæ•°æ¨¡å¼ï¼Œæ¯ chunk {max_rows_per_chunk} è¡Œ")
        chunks = distribute_assets_and_chunk(
            html_content,
            max_rows_per_chunk=max_rows_per_chunk,
            max_tokens_per_chunk=None
        )
    print(f"ğŸ”ª åˆ‡åˆ†å®Œæˆï¼šå…±ç”Ÿæˆ {len(chunks)} ä¸ªç‰‡æ®µ")

    # ä¿å­˜ chunk ç»“æœï¼ˆæœ€ç»ˆç»“æœä¸åŸæ–‡ä»¶åŒåï¼Œæ–¹ä¾¿ç›´æ¥ä½¿ç”¨ï¼‰
    chunk_path = source_path.with_suffix(".html")

    formatted_separator = f"\n\n{separator}\n\n"
    merged_content = formatted_separator.join(chunks)

    try:
        chunk_path.write_text(merged_content, encoding="utf-8")
        print(f"âœ… Chunk æ–‡ä»¶å·²ä¿å­˜: {chunk_path.absolute()}")
    except IOError as e:
        print(f"âŒ å†™å…¥ Chunk æ–‡ä»¶å¤±è´¥: {e}")
        return None

    # === å®Œæˆ ===
    print("\n" + "=" * 50)
    print("ğŸ‰ æµæ°´çº¿æ‰§è¡Œå®Œæˆï¼")
    print(f"   ğŸ“„ ä¸­é—´ç»“æœ (HTML): {html_path}")
    print(f"   ğŸ“„ æœ€ç»ˆç»“æœ (Chunks): {chunk_path}")
    print(f"   ğŸ”¢ Chunk æ•°é‡: {len(chunks)}")
    print(f"   ğŸ”‘ åˆ†éš”ç¬¦: {separator}")
    print(f"   ğŸ’¡ æç¤º: æœ€ç»ˆç»“æœä¸åŸæ–‡ä»¶åŒåï¼Œå¯ç›´æ¥ä½¿ç”¨")
    print("=" * 50)

    return {
        "html_path": html_path,
        "chunk_path": str(chunk_path),
        "chunk_count": len(chunks),
    }


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="Excel è½¬ HTML å®Œæ•´æµæ°´çº¿ï¼ˆå¢å¼ºç‰ˆ + Chunk åˆ‡åˆ†ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python pipeline.py input.xlsx
  python pipeline.py input.xlsx -k "è´¢åŠ¡æŠ¥è¡¨" "å¹´åº¦æ”¶å…¥"
  python pipeline.py input.xlsx -t 512          # åŸºäº 512 tokens è‡ªåŠ¨è®¡ç®—è¡Œæ•°
  python pipeline.py input.xlsx -r 5            # å›ºå®šæ¯ chunk 5 è¡Œ
  python pipeline.py input.xlsx -t 1024 -s "---SPLIT---"
        """,
    )
    parser.add_argument("excel_file", help="è¦è½¬æ¢çš„ Excel æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "-k", "--keywords", nargs="+", help="å…³é”®æ£€ç´¢è¯ï¼ˆç”¨äºå¹½çµæ ‡é¢˜ï¼‰"
    )
    parser.add_argument(
        "-r",
        "--max-rows",
        type=int,
        default=None,
        help="æ¯ä¸ª chunk çš„æœ€å¤§æ•°æ®è¡Œæ•°ï¼ˆæŒ‡å®šåå¿½ç•¥ -t å‚æ•°ï¼‰",
    )
    parser.add_argument(
        "-t",
        "--target-tokens",
        type=int,
        default=512,
        help="ç›®æ ‡ token æ•°ï¼Œè‡ªåŠ¨è®¡ç®—è¡Œæ•°ï¼ˆé»˜è®¤: 512ï¼‰",
    )
    parser.add_argument(
        "-s",
        "--separator",
        default="!!!_CHUNK_BREAK_!!!",
        help="chunk ä¹‹é—´çš„åˆ†éš”ç¬¦ï¼ˆé»˜è®¤: !!!_CHUNK_BREAK_!!!ï¼‰",
    )

    args = parser.parse_args()

    run_pipeline(
        excel_path=args.excel_file,
        keywords=args.keywords,
        max_rows_per_chunk=args.max_rows,
        target_tokens=args.target_tokens,
        separator=args.separator,
    )


if __name__ == "__main__":
    main()
